{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05200146",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "- Full tutorial reference: https://www.tensorflow.org/tutorials/keras/text_classification\n",
    "- This tutorial demonstrates text classification and will train a binary classifier to perform sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93e9d0",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9982b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26664876",
   "metadata": {},
   "source": [
    "### Sentiment analysis\n",
    "- This tutorial trains a sentiment analysis model to classify movie reviews as *positive* or *negative*, based on the review.\n",
    "- Binary (two-class) classification is an critical machine learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f84de1",
   "metadata": {},
   "source": [
    "### Download and explore IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c4f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84125825/84125825 [==============================] - 30s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "# dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url, untar=True, cache_dir='.', cache_subdir='')\n",
    "# dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea2afa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e00bf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsup',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075ca9d",
   "metadata": {},
   "source": [
    "### Load the dataset \n",
    "- It is required to load the data off disk.\n",
    "- To do so, *text_dataset_from_directory* utility from *tf.keras.utils* module would be helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "468b108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'unsup' folder for preparing binary classification 'pos' and 'neg'\n",
    "shutil.rmtree(os.path.join(train_dir, 'unsup'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb7272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory('aclImdb/train',\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          validation_split=0.2, # create a validation set using an 80:20 split\n",
    "                                                          subset='training',\n",
    "                                                          seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06e6c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory('aclImdb/train',\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          validation_split=0.2, # create a validation set using an 80:20 split\n",
    "                                                          subset='validation',\n",
    "                                                          seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4cadf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory('aclImdb/test',\n",
    "                                                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa8d82",
   "metadata": {},
   "source": [
    "### Prepare the dataset for training\n",
    "- Before training, standardization, tokenization and vectorization are required:\n",
    "    - Standardization refers to preprocessing the text (remove punctuation or HTML elements to simplify the dataset).\n",
    "    - Tokenization refers to splitting strings into tokens.\n",
    "    - Vectorization refers to converting tokens into numbers to prepare neural network training.\n",
    "- All the above steps can be done by using the helpful *tf.keras.layers.TextVectorization* layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d555256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom standardization function to remove the HTML elements\n",
    "def custom_standardization(data):\n",
    "    lowercase = tf.strings.lower(data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b78f8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000 # maximum token number\n",
    "sequence_length = 250 # cause the layer to pad or truncate sequences to exactly sequence_length values\n",
    "\n",
    "text_vectorize_layer = tf.keras.layers.TextVectorization(standardize=custom_standardization,\n",
    "                                                        max_tokens=max_features,\n",
    "                                                        output_mode='int', # create unique integer indices for each token \n",
    "                                                        output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62969592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call adapt to fit the state of the preprocessing layer to the dataset\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "text_vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10223c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1) # axis=-1 adds an inner most dimension\n",
    "    return text_vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c21018b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c52f0",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance\n",
    "- *.cache()* keeps data in memory after it is loaded off disk.\n",
    "- *.prefetch()* overlaps data preprocessing and model execution while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07cdcdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e16ab83",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "- The *tf.keras.layers* are stacked sequentially to build the model:\n",
    "    - Embedding layer (first layer) takes the integer-encoded reviews and looks up an embedding vector for each word-index.\n",
    "    - GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension.\n",
    "- After GlobalAveragePooling1D layer, the fixed-length output vector goes through a dense layer with 16 hidden units.\n",
    "- Final layer is densely connected with a single output node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c04bc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          160016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_features+1, output_dim=embedding_dim),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d3fe041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd6b600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 29s 42ms/step - loss: 0.6642 - binary_accuracy: 0.6916 - val_loss: 0.6150 - val_binary_accuracy: 0.7746\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 5s 9ms/step - loss: 0.5492 - binary_accuracy: 0.8022 - val_loss: 0.4976 - val_binary_accuracy: 0.8230\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.4450 - binary_accuracy: 0.8456 - val_loss: 0.4193 - val_binary_accuracy: 0.8472\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3791 - binary_accuracy: 0.8653 - val_loss: 0.3729 - val_binary_accuracy: 0.8616\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3375 - binary_accuracy: 0.8775 - val_loss: 0.3448 - val_binary_accuracy: 0.8664\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3074 - binary_accuracy: 0.8882 - val_loss: 0.3252 - val_binary_accuracy: 0.8704\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2840 - binary_accuracy: 0.8970 - val_loss: 0.3117 - val_binary_accuracy: 0.8736\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2657 - binary_accuracy: 0.9021 - val_loss: 0.3020 - val_binary_accuracy: 0.8752\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2493 - binary_accuracy: 0.9086 - val_loss: 0.2952 - val_binary_accuracy: 0.8778\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.2345 - binary_accuracy: 0.9150 - val_loss: 0.2905 - val_binary_accuracy: 0.8810\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                   validation_data=val_ds,\n",
    "                   epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b11a8",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62315f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 28s 36ms/step - loss: 0.3102 - binary_accuracy: 0.8738\n",
      "Loss, Accuracy: 0.3102016746997833 0.8737999796867371\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_ds)\n",
    "print('Loss, Accuracy:', result[0], result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd85d3e",
   "metadata": {},
   "source": [
    "### Export the model\n",
    "- It is possible to include *TextVectorization* layer inside the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51fed903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 8s 9ms/step - loss: 0.3102 - accuracy: 0.8738\n",
      "Loss, Accuracy: 0.310201495885849 0.8737999796867371\n"
     ]
    }
   ],
   "source": [
    "model_export = tf.keras.Sequential([\n",
    "    text_vectorize_layer,\n",
    "    model,\n",
    "    tf.keras.layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model_export.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), # since sigmoid activation function is in the last layer, from_logits=False\n",
    "                    metrics=['accuracy']\n",
    "                    )\n",
    "\n",
    "result = model_export.evaluate(raw_test_ds)\n",
    "print('Loss, Accuracy:', result[0], result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc274a7",
   "metadata": {},
   "source": [
    "### Prediction using new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95a08f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.61574024],\n",
       "       [0.44878286],\n",
       "       [0.3458126 ],\n",
       "       [0.36650437]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = ['The movie was fun!', 'The movie was okay.', 'The movie was boring.', 'The movie was terrible.']\n",
    "model_export.predict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f51597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2017 Fran√ßois Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
